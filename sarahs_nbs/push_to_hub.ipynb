{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, cast\n",
    "import argparse\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "\n",
    "print(original_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "post_import = os.getcwd()\n",
    "print(post_import)\n",
    "\n",
    "os.chdir(original_dir)\n",
    "\n",
    "from src.bert_layers.configuration_bert import FlexBertConfig\n",
    "from src.bert_layers.model import init_mlm_model_from_pretrained\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig\n",
    "\n",
    "import datasets\n",
    "\n",
    "# Add folder root to path to allow us to use relative imports regardless of what directory the script is run from\n",
    "sys.path.append(os.path.dirname(os.path.realpath(__file__)))\n",
    "\n",
    "from composer import Evaluator, Trainer, algorithms\n",
    "from composer.callbacks import LRMonitor, MemoryMonitor, OptimizerMonitor, RuntimeEstimator, SpeedMonitor\n",
    "from composer.core import DataSpec\n",
    "from composer.core.types import Dataset\n",
    "from composer.loggers import WandBLogger\n",
    "from composer.optim import DecoupledAdamW\n",
    "from composer.optim.scheduler import (\n",
    "    ConstantWithWarmupScheduler,\n",
    "    CosineAnnealingWithWarmupScheduler,\n",
    "    LinearWithWarmupScheduler,\n",
    ")\n",
    "from composer.utils import dist, reproducibility\n",
    "from composer.utils.checkpoint import _ensure_valid_checkpoint\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from omegaconf import OmegaConf as om\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "\n",
    "import src.evals.data as data_module\n",
    "import src.flex_bert as flex_bert_module\n",
    "import src.hf_bert as hf_bert_module\n",
    "import src.mosaic_bert as mosaic_bert_module\n",
    "import src.text_data as text_data_module\n",
    "from src.callbacks.dataloader_speed import DataloaderSpeedMonitor\n",
    "from src.callbacks.log_grad_norm import LogGradNorm\n",
    "from src.callbacks.packing_efficiency import PackingEfficency\n",
    "from src.callbacks.scheduled_gc import ScheduledGarbageCollector\n",
    "from src.scheduler import CosineInverseSqrtScheduler, OneMinusSqrtScheduler, WarmupStableDecayScheduler\n",
    "from src.sequence_packer import get_num_samples_in_packed_batch, split_packed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = flex_bert_module.create_modern_bert_mlm(\n",
    "            pretrained_model_name=cfg.pretrained_model_name,\n",
    "            pretrained_checkpoint=cfg.get(\"pretrained_checkpoint\", None),\n",
    "            model_config=cfg.get(\"model_config\", None),\n",
    "            tokenizer_name=cfg.get(\"tokenizer_name\", None),\n",
    "            gradient_checkpointing=cfg.get(\"gradient_checkpointing\", None),\n",
    "            recompute_metric_loss=cfg.get(\"recompute_metric_loss\", False),\n",
    "            disable_train_metrics=cfg.get(\"disable_train_metrics\", False),\n",
    "            use_dora=cfg.get(\"use_dora\", False),\n",
    "            mixed_mlm=cfg.get(\"mixed_mlm\", False),\n",
    "            checkpoint_dict=cfg.get(\"checkpoint_dict\", None),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"sarahpann/demo\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
