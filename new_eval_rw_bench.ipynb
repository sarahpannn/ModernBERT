{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "import peft\n",
    "from peft import AutoPeftModel\n",
    "\n",
    "import sys\n",
    "import src.evals.data as data_module\n",
    "\n",
    "import torch\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = \"answerdotai/ModernBERT-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 352/352 [00:00<00:00, 2.22kB/s]\n",
      "Downloading data: 100%|██████████| 3.90M/3.90M [00:01<00:00, 3.90MB/s]\n",
      "Generating train split: 100%|██████████| 2488/2488 [00:00<00:00, 133203.50 examples/s]\n",
      "Map: 100%|██████████| 2488/2488 [00:00<00:00, 2707.09 examples/s]\n",
      "Downloading readme: 100%|██████████| 348/348 [00:00<00:00, 2.75kB/s]\n",
      "Downloading data: 100%|██████████| 403k/403k [00:00<00:00, 2.12MB/s]\n",
      "Generating train split: 100%|██████████| 464/464 [00:00<00:00, 121574.03 examples/s]\n",
      "Map: 100%|██████████| 464/464 [00:00<00:00, 5089.47 examples/s]\n",
      "Downloading readme: 100%|██████████| 352/352 [00:00<00:00, 2.69kB/s]\n",
      "Downloading data: 100%|██████████| 1.06M/1.06M [00:00<00:00, 4.62MB/s]\n",
      "Generating train split: 100%|██████████| 1431/1431 [00:00<00:00, 226270.41 examples/s]\n",
      "Map: 100%|██████████| 1431/1431 [00:00<00:00, 2864.60 examples/s]\n",
      "Downloading readme: 100%|██████████| 350/350 [00:00<00:00, 2.08kB/s]\n",
      "Downloading data: 100%|██████████| 665k/665k [00:00<00:00, 2.81MB/s]\n",
      "Generating train split: 100%|██████████| 740/740 [00:00<00:00, 204250.13 examples/s]\n",
      "Map: 100%|██████████| 740/740 [00:00<00:00, 5342.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "chat = data_module.create_preference_to_flan_style_dataset(\n",
    "    task = \"sarahpann/rwb_chat\",\n",
    "    split = \"train\",\n",
    "    tokenizer_name = tokenizer,\n",
    "    max_seq_length = 3600,\n",
    "    prefix = \"Which response is the most helpful, relevant, and correct? \",\n",
    "\n",
    "    dataset_name=\"sarahpann/rwb_chat\",\n",
    "    dataset_subset=\"\",\n",
    "    task_column_names={\"sarahpann/rwb_chat\": ('chosen', 'rejected', 'og_dataset')}\n",
    ")\n",
    "\n",
    "chat_hard = data_module.create_preference_to_flan_style_dataset(\n",
    "    task = \"sarahpann/rwb_chat_hard\",\n",
    "    split = \"train\",\n",
    "    tokenizer_name = tokenizer,\n",
    "    max_seq_length = 3600,\n",
    "    prefix = \"Which response is the most helpful, relevant, and correct? \",\n",
    "\n",
    "    dataset_name=\"sarahpann/rwb_chat_hard\",\n",
    "    dataset_subset=\"\",\n",
    "    task_column_names={\"sarahpann/rwb_chat_hard\": ('chosen', 'rejected', 'og_dataset')}\n",
    ")\n",
    "\n",
    "reasoning = data_module.create_preference_to_flan_style_dataset(\n",
    "    task=\"sarahpann/rwb_reasoning\",\n",
    "    split='train',\n",
    "    tokenizer_name=tokenizer,\n",
    "    max_seq_length=3600,\n",
    "    prefix=\"Determine which response is the best choice based on mathematical or programming accuracy. \",\n",
    "\n",
    "    dataset_name=\"sarahpann/rwb_reasoning\",\n",
    "    dataset_subset=\"\",\n",
    "    task_column_names={\"sarahpann/rwb_reasoning\": ('chosen', 'rejected', 'og_dataset')}\n",
    ")\n",
    "\n",
    "safety = data_module.create_preference_to_flan_style_dataset(\n",
    "    task=\"sarahpann/rwb_safety\",\n",
    "    split='train',\n",
    "    tokenizer_name=tokenizer,\n",
    "    max_seq_length=3600,\n",
    "    prefix=\"Which response is the most helpful, relevant, and correct? \",\n",
    "\n",
    "    dataset_name=\"sarahpann/rwb_safety\",\n",
    "    dataset_subset=\"\",\n",
    "    task_column_names={\"sarahpann/rwb_safety\": ('chosen', 'rejected', 'og_dataset')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForMaskedLM.from_pretrained(\"sarahpann/reasoning_model_large\")\n",
    "model = AutoPeftModel.from_pretrained(\"sarahpann/reasoning_model_large\", \n",
    "                                      attn_implementation='flash_attention_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "chat_hard.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "reasoning.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "safety.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_loader = torch.utils.data.DataLoader(chat, batch_size=1, shuffle=False)\n",
    "chat_hard_loader = torch.utils.data.DataLoader(chat_hard, batch_size=1, shuffle=False)\n",
    "reasoning_loader = torch.utils.data.DataLoader(reasoning, batch_size=1, shuffle=False)\n",
    "safety_loader = torch.utils.data.DataLoader(safety, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_tokenizer = AutoTokenizer.from_pretrained(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(model, subject_dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, example in tqdm(enumerate(subject_dataloader)):\n",
    "            input_ids = example['input_ids'].clone()\n",
    "            input_ids[:, -2] = real_tokenizer.mask_token_id\n",
    "            input_ids = input_ids.to(\"cuda\")\n",
    "            attention_mask = example['attention_mask'].to(\"cuda\")\n",
    "\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = output.logits\n",
    "            pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # print(output)\n",
    "            if not i % 400:\n",
    "                print(\"prediction: \", pred[0, -2])\n",
    "                print(\"label: \", example['input_ids'][0, -2])\n",
    "\n",
    "            # print(real_tokenizer.decode(input_ids[0]))\n",
    "            if pred[0, -2] == example['input_ids'][0, -2]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    print(f\"Accuracy: {correct / total}\")\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataCollatorForFlanStyleQuestionAnswering(transformers.DataCollatorForLanguageModeling):\n",
    "    def __init__(self, tokenizer, mlm_probability=0.15, prompt=None):\n",
    "        super().__init__(tokenizer=tokenizer, mlm_probability=mlm_probability)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mlm_probability = mlm_probability\n",
    "\n",
    "    def torch_mask_tokens(self, inputs, special_tokens_mask):\n",
    "        \"\"\"\n",
    "        Mask the last non-SEP non-PAD token in the sequence.\n",
    "        \"\"\"\n",
    "        labels = inputs.clone()\n",
    "\n",
    "        pad_token_id = self.tokenizer.pad_token_id\n",
    "        sep_token_id = self.tokenizer.sep_token_id\n",
    "        mask_token_id = self.tokenizer.mask_token_id\n",
    "\n",
    "        batch_size, seq_length = inputs.shape\n",
    "\n",
    "        if special_tokens_mask is None:\n",
    "            special_tokens_mask = [\n",
    "                self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "            ]\n",
    "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "\n",
    "        # Find the last [SEP] token index in each sequence\n",
    "        sep_positions = (inputs == sep_token_id).int()\n",
    "        last_sep_indices = (sep_positions * torch.arange(seq_length, device=inputs.device)).argmax(dim=1)\n",
    "\n",
    "        # Initialize a mask for which token to replace with [MASK]\n",
    "        mask_positions = torch.zeros_like(inputs, dtype=torch.bool)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            sep_index = last_sep_indices[i].item()\n",
    "\n",
    "            # Traverse backward to find the second-to-last valid token\n",
    "            for j in range(sep_index - 1, -1, -1):\n",
    "                if inputs[i, j] not in {pad_token_id, sep_token_id}:\n",
    "                    mask_positions[i, j] = True\n",
    "                    break\n",
    "\n",
    "        # Apply mask\n",
    "        inputs[mask_positions] = mask_token_id\n",
    "        labels[~mask_positions] = -100  # Only keep masked token for loss calculation\n",
    "\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CustomDataCollatorForFlanStyleQuestionAnswering(\n",
    "    tokenizer=real_tokenizer,\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "alternative_dl = torch.utils.data.DataLoader(reasoning, batch_size=1, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.flex_bert import EfficientHuggingFaceModel\n",
    "from composer.metrics.nlp import MaskedAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [MaskedAccuracy(ignore_index=-100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = EfficientHuggingFaceModel(\n",
    "    model=model,\n",
    "    tokenizer=real_tokenizer,\n",
    "    use_logits=True,\n",
    "    metrics=metrics,\n",
    "    eval_metrics=metrics,\n",
    "    allow_embedding_resizing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:00, 1272.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [00:00, 1234.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "633it [00:00, 1231.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "885it [00:00, 1244.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1131it [00:00, 1139.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1431it [00:01, 1191.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n",
      "{17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_dataset_with_collator(model, dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, example in tqdm(enumerate(dataloader)):\n",
    "            labels = example['labels']\n",
    "            # get all nonmasked tokens\n",
    "            nonzero_labels = labels[labels != -100]\n",
    "            print(set(nonzero_labels.tolist()))\n",
    "            \n",
    "    # print(f\"Accuracy: {correct / total}\")\n",
    "    # return correct / total\n",
    "eval_dataset_with_collator(model, alternative_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:22,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor(17, device='cuda:0')\n",
      "label:  tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403it [00:44, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor(17, device='cuda:0')\n",
      "label:  tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "804it [01:07, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor(17, device='cuda:0')\n",
      "label:  tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1204it [01:32, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor(18, device='cuda:0')\n",
      "label:  tensor(17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1431it [01:45, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7120894479385046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# chat_acc = eval_dataset(model, chat_loader)\n",
    "# chat_hard_acc = eval_dataset(model, chat_hard_loader)\n",
    "reasoning_acc = eval_dataset(model, reasoning_loader)\n",
    "# safety_acc = eval_dataset(model, safety_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': 0.7946141479099679, 'chat_hard': 0.2521551724137931, 'reasoning': 0.76659678546471, 'safety': 0.7918918918918919}\n"
     ]
    }
   ],
   "source": [
    "final_results = {\n",
    "    \"chat\": chat_acc,\n",
    "    \"chat_hard\": chat_hard_acc,\n",
    "    \"reasoning\": reasoning_acc,\n",
    "    \"safety\": safety_acc\n",
    "}\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876919073622352"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for chat\n",
    "0.8657556270096463 * (1 - 0.157) + 0.36853448275862066 * (0.157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reasoning\n",
    "0.3305380852550664"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
